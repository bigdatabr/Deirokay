"""
Module for BaseStatement and builtin Deirokay statements.
"""

from typing import Optional

import numpy as np
import pandas as pd
from jinja2 import BaseLoader
from jinja2.nativetypes import NativeEnvironment

from .fs import FileSystem
from .history_template import get_series


class BaseStatement:
    """Base abstract statement class for all Deirokay statements.

    Parameters
    ----------
    options : dict
        Statement parameters provided by user.
    read_from : Optional[FileSystem], optional
        Where read past validation logs from
        (necessary for templated moving statistics).
        By default None.

    Attributes
    ----------
    name : str
        Statement name when referred in Validation Documents (only
        valid for non-custom statements).
    expected_parameters : List[str]
        Parameters expected for this statement.
    table_only : bool
        Whether or not this statement in applicable only to the entire
        table, instead of scoped columns.
    jinjaenv : NativeEnvironment
        Jinja Environment to use when rendering templates. Only for
        advanced users.
    """

    name = 'base_statement'
    expected_parameters = ['type', 'severity', 'location']
    table_only = False
    jinjaenv = NativeEnvironment(loader=BaseLoader())

    def __init__(self, options: dict, read_from: Optional[FileSystem] = None):
        self._validate_options(options)
        self.options = options
        self._read_from = read_from
        self._parse_options()

    def _validate_options(self, options: dict):
        """Make sure all providded statement parameters are expected
        by statement classes"""
        cls = type(self)
        unexpected_parameters = [
            option for option in options
            if option not in (cls.expected_parameters +
                              BaseStatement.expected_parameters)
        ]
        if unexpected_parameters:
            raise ValueError(
                f'Invalid parameters passed to {cls.__name__} statement: '
                f'{unexpected_parameters}\n'
                f'The valid parameters are: {cls.expected_parameters}'
            )

    def _parse_options(self):
        """Render Jinja templates in statement parameters."""
        for key, value in self.options.items():
            if isinstance(value, str):
                rendered = (
                    BaseStatement.jinjaenv.from_string(value)
                    .render(
                        series=lambda x, y: get_series(x, y, self._read_from)
                    )
                )
                self.options[key] = rendered

    def __call__(self, df: pd.DataFrame):
        """Run statement instance."""
        internal_report = self.report(df)
        result = self.result(internal_report)

        final_report = {
            'detail': internal_report,
            'result': result
        }
        return final_report

    def report(self, df: pd.DataFrame) -> dict:
        """Receive a DataFrame containing only columns on the scope of
        validation and returns a report of related metrics that can
        be used later to declare this Statement as fulfilled or
        failed.

        Parameters
        ----------
        df : pd.DataFrame
            The scoped DataFrame columns to be analysed in this report
            by this statement.

        Returns
        -------
        dict
            A dictionary of useful statistics about the target columns.
        """
        return {}

    def result(self, report: dict) -> bool:
        """Receive the report previously generated and declare this
        statement as either fulfilled (True) or failed (False).

        Parameters
        ----------
        report : dict
            Report generated by `report` method. Should ideally
            contain all statistics necessary to evaluate the statement
            validity.

        Returns
        -------
        bool
            Whether or not this statement passed.
        """
        return True

    @staticmethod
    def profile(df: pd.DataFrame) -> dict:
        """Given a template data table, generate a statement dict
        from it.

        Parameters
        ----------
        df : pd.DataFrame
            The DataFrame to be used as template.

        Returns
        -------
        dict
            Statement dict.
        """
        raise NotImplementedError


# docstr-coverage:inherited
class Unique(BaseStatement):
    """Check if the rows of a scoped DataFrame are unique."""

    name = 'unique'
    expected_parameters = ['at_least_%']

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        self.at_least_perc = self.options.get('at_least_%', 100.0)

    # docstr-coverage:inherited
    def report(self, df):
        unique = ~df.duplicated(keep=False)

        report = {
            'unique_rows': int(unique.sum()),
            'unique_rows_%': float(100.0*unique.sum()/len(unique)),
        }
        return report

    # docstr-coverage:inherited
    def result(self, report):
        return report.get('unique_rows_%') >= self.at_least_perc

    # docstr-coverage:inherited
    @staticmethod
    def profile(df):
        unique = ~df.duplicated(keep=False)

        statement = {
            'type': 'unique',
            'at_least_%': float(100.0*unique.sum()/len(unique)),
        }
        return statement


# docstr-coverage:inherited
class NotNull(BaseStatement):
    """Check if the rows of a scoped DataFrame are not null."""

    name = 'not_null'
    expected_parameters = ['at_least_%', 'at_most_%', 'multicolumn_logic']

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        self.at_least_perc = self.options.get('at_least_%', 100.0)
        self.at_most_perc = self.options.get('at_most_%', 100.0)
        self.multicolumn_logic = self.options.get('multicolumn_logic', 'any')

        assert self.multicolumn_logic in ('any', 'all')

    # docstr-coverage:inherited
    def report(self, df):
        if self.multicolumn_logic == 'all':
            #  REMINDER: ~all == any
            not_nulls = ~df.isnull().any(axis=1)
        else:
            not_nulls = ~df.isnull().all(axis=1)

        report = {
            'null_rows': int((~not_nulls).sum()),
            'null_rows_%': float(100.0*(~not_nulls).sum()/len(not_nulls)),
            'not_null_rows': int(not_nulls.sum()),
            'not_null_rows_%': float(100.0*not_nulls.sum()/len(not_nulls)),
        }
        return report

    # docstr-coverage:inherited
    def result(self, report):
        if not report.get('not_null_rows_%') >= self.at_least_perc:
            return False
        if not report.get('not_null_rows_%') <= self.at_most_perc:
            return False
        return True

    # docstr-coverage:inherited
    @staticmethod
    def profile(df):
        not_nulls = ~df.isnull().all(axis=1)

        statement = {
            'type': 'not_null',
            'multicolumn_logic': 'any',
            'at_least_%': float(100.0*not_nulls.sum()/len(not_nulls)),
            'at_most_%': float(100.0*not_nulls.sum()/len(not_nulls))
        }
        return statement


# docstr-coverage:inherited
class RowCount(BaseStatement):
    """Check if the number of rows in a DataFrame is within a
    range."""

    name = 'row_count'
    expected_parameters = ['min', 'max']
    table_only = True

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        self.min = self.options.get('min', None)
        self.max = self.options.get('max', None)

    # docstr-coverage:inherited
    def report(self, df):
        row_count = len(df)

        report = {
            'rows': row_count,
        }
        return report

    # docstr-coverage:inherited
    def result(self, report):
        row_count = report['rows']

        if self.min is not None:
            if not row_count >= self.min:
                return False
        if self.max is not None:
            if not row_count <= self.max:
                return False
        return True

    # docstr-coverage:inherited
    @staticmethod
    def profile(df):
        row_count = len(df)

        statement = {
            'type': 'row_count',
            'min': row_count,
            'max': row_count,
        }
        return statement


class Contain(BaseStatement):
    """
    Checks if a given column contains specific values. We can also check the
    number of occurrences of that values, asserting a minimum or maximum value
    of appearances.
    """
    name = 'contain'
    expected_parameters = [
        'rule',
        'values',
        'occurrences_per_value',
        'min_occurrences',
        'max_occurrences'
    ]
    table_only = False

    def __init__(self, *args, **kwargs):
        """
        Check if the values in a given column are in a list of expected
        values.
        """
        super().__init__(*args, **kwargs)

        self.rule = self.options.get('rule', None)
        self.values = self.options.get('values', None)

        self.min_occurrences = self.options.get('min_occurrences', None)
        self.max_occurrences = self.options.get('max_occurrences', None)
        self.occurrences_per_value = self.options.get(
            'occurrences_per_value', {}
        )

        self._set_default_minmax_occurrences()
        self._assert_parameters()

    def _set_default_minmax_occurrences(self):
        min_occurrences_rule_default = {
            'all': 1,
            'only': 0,
            'all_and_only': 1
        }
        max_occurrences_rule_default = {
            'all': np.inf,
            'only': np.inf,
            'all_and_only': np.inf
        }

        if self.min_occurrences is None:
            self.min_occurrences = min_occurrences_rule_default[self.rule]
        if self.max_occurrences is None:
            self.max_occurrences = max_occurrences_rule_default[self.rule]

    def _assert_parameters(self):
        assert self.rule in ('all', 'only', 'all_and_only')
        assert self.min_occurrences >= 0
        assert self.max_occurrences >= 0

    # docstr-coverage:inherited
    def report(self, df):
        count_isin = {}
        for col in df.columns:
            count_isin[col] = df[col].value_counts().to_dict()

        report = {
            'col_value_count': count_isin,
        }
        return report

    # docstr-coverage:inherited
    def result(self, report):
        col_value_count = report['col_value_count']
        self._set_min_max_boundaries(col_value_count)
        self._set_values_scope()

        check_interval = self._check_interval(col_value_count)
        check_rule = self._check_rule(col_value_count)

        return check_rule and check_interval

    def _set_min_max_boundaries(self, col_value_count):
        """
        Sets, for each column/value, the maxmimum and minimum number of
        expected occurrences. They are set with `self.max_occurrences`
        and `self.min_occurrences` attributes. Also, we can specify
        special boundaries for one or more values, using
        `self.occurrences_per_value` attribute.

        Parameters
        ----------
        col_value_count: dict
            Description of columns and quantities of occurrences per
            value, calculated in `self.report()` method
        """
        min_max_boundaries = {}

        # Global boundaries
        for col, values_in_col in col_value_count.items():
            min_max_boundaries[col] = {}
            for value in self.values:
                min_max_value = min_max_boundaries[col]
                min_max_value.update({
                    value: {
                        'min_occurrences': self.min_occurrences,
                        'max_occurrences': self.max_occurrences
                    }
                })

                min_max_boundaries[col] = min_max_value

        # Dedicated boundaries
        for col in col_value_count.keys():
            if self.occurrences_per_value:
                for occurrence in self.occurrences_per_value:
                    values = []
                    if type(occurrence['values']) == str:
                        values.append(occurrence['values'])
                    else:
                        values = occurrence['values']

                    for value in values:
                        min_max_boundaries[col][value][
                            'min_occurrences'
                        ] = occurrence.get(
                            'min_occurrences', self.min_occurrences
                        )

                        min_max_boundaries[col][value][
                            'max_occurrences'
                        ] = occurrence.get(
                            'max_occurrences', self.max_occurrences
                        )

        self.min_max_boundaries = min_max_boundaries

    def _set_values_scope(self):
        """
        Sets the scope of values to be analyzed according to the
        given `self.rule`. Excludes the cases of values where
        its corresponding `max_occurrences` is zero, because
        these cases doesn't matter for the `rule` analysis, as
        they must be absent in the column.
        """
        values_scope_filter = {}
        for col in self.min_max_boundaries.keys():
            values_col = []
            for value in self.min_max_boundaries[col]:
                if self.min_max_boundaries[col][value]['max_occurrences'] != 0:
                    values_col.append(value)
                values_scope_filter[col] = values_col
        self.values_scope_filter = values_scope_filter

    def _check_interval(self, col_value_count):
        """
        Checks if each value is inside an interval of min and max number
        of occurrencies. These values are set globally in
        `self.min_occurrencies` and `self.max_occurrencies`, but the
        user can specify dedicated intervals for a given value inside
        `self.occurrences_per_value`
        """
        for col, values in col_value_count.items():
            for value in self.values:
                min_value = self.min_max_boundaries[col][value][
                    'min_occurrences'
                ]
                max_value = self.min_max_boundaries[col][value][
                    'max_occurrences'
                ]
                if value in values.keys():
                    if not (
                        min_value <= col_value_count[col][value] <= max_value
                    ):
                        return False
                else:
                    if self.rule != 'only' and max_value != 0\
                       and min_value != 0:
                        return False
        return True

    def _check_rule(self, col_value_count):
        """
        Checks if given columns attend the given requirements
        of presence or absence of values, according to a criteria specified in
        `self.rule`

        Parameters
        ----------
        col_value_count: dict
            Got from `report` method, it contains the count of occurrences
            for each column for each value

        Notes
        -----
        `self.rule` parameter defines the criteria to use for checking the
        presence or absence of values in a column. Its values should be:

        * all: all the values in `self.values` are present in the column, but
          there can be other values also
        * only: only the values in `self.values` (but not necessarilly all of
          them) are present in the given column
        * all_and_only: the column must contain exactly the values in
          `self.values` - neither more than less. As the name says, it is an
          `and` boolean operation between `all` and `only` modes
        """
        if self.rule == 'all':
            return self._check_all(col_value_count)
        elif self.rule == 'only':
            return self._check_only(col_value_count)
        elif self.rule == 'all_and_only':
            is_check_all = self._check_all(col_value_count)
            is_check_only = self._check_only(col_value_count)
            return is_check_all and is_check_only

    def _check_all(self, col_value_count):
        """
        Checks if values in df contains all the expected values
        """
        for col in col_value_count.keys():
            values_in_col = set(col_value_count[col].keys())
            values = set(self.values_scope_filter[col])
            if values - values_in_col != set():
                return False
        return True

    def _check_only(self, col_value_count):
        """
        Checks if all values in df are inside the expected values
        """
        for col in col_value_count.keys():
            values_in_col = set(col_value_count[col].keys())
            values = set(self.values_scope_filter[col])
            if values_in_col - values:
                return False
        return True

    # docstr-coverage:inherited
    @staticmethod
    def profile(df):
        if {np.dtype('<M8[ns]'), np.dtype('>M8[ns]')}.intersection(
            set(df.dtypes.tolist())
        ):
            raise NotImplementedError("Deirokay can't serialize datetime64")

        min_occurrences = {x: df[x].value_counts().min() for x in df.columns}
        max_occurrences = {x: df[x].value_counts().max() for x in df.columns}

        min_occurrences = min(list(min_occurrences.values()))
        max_occurrences = max(list(max_occurrences.values()))

        values = [list(df[x].unique()) for x in df.columns]
        values = list(set().union(*values))
        try:
            values.sort()
        except TypeError:
            raise NotImplementedError("Can't handle mixed types")

        return {
            'type': 'contain',
            'rule': 'all_and_only',
            'values': values,
            'min_occurrences': min_occurrences,
            'max_occurrences': max_occurrences
        }
